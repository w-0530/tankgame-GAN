#!/usr/bin/env python3
"""
å¦å…‹æ¸¸æˆAIè§‚çœ‹è„šæœ¬
åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œè§‚çœ‹AIç©æ¸¸æˆ
"""

import torch
import numpy as np
import tankgame
import time
import argparse

# å¯¼å…¥è®­ç»ƒè„šæœ¬ä¸­çš„æ¨¡å‹å’Œæ™ºèƒ½ä½“
from train_quick_test import CompactRobustNet, CompactRobustAgent, MOVEMENT_ACTIONS, AIM_ACTIONS

class DemoAgent:
    """æ¼”ç¤ºæ™ºèƒ½ä½“ - åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¸¸æˆæ¼”ç¤º"""
    
    def __init__(self, model_path="compact_robust_model.pth"):
        self.model = CompactRobustNet()
        self.model.load_state_dict(torch.load(model_path, map_location='cpu'))
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        print(f"âœ“ å·²åŠ è½½æ¨¡å‹: {model_path}")
        print(f"âœ“ æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
    
    def get_action(self, state):
        """æ ¹æ®çŠ¶æ€è·å–åŠ¨ä½œï¼ˆæ— æ¢ç´¢ï¼Œçº¯è´ªå¿ƒï¼‰"""
        state_tensor = torch.FloatTensor(state).unsqueeze(0)
        
        with torch.no_grad():
            movement_q, aim_q = self.model(state_tensor)
            movement_action = movement_q.argmax().item()
            aim_action = aim_q.argmax().item()
        
        return movement_action, aim_action
    
    def get_combined_action(self, movement_action, aim_action):
        """å°†åˆ†ç¦»çš„åŠ¨ä½œè½¬æ¢ä¸ºæ¸¸æˆåŠ¨ä½œåˆ—è¡¨"""
        actions = []
        if movement_action in MOVEMENT_ACTIONS:
            actions.append(MOVEMENT_ACTIONS[movement_action])
        if aim_action in AIM_ACTIONS:
            actions.append(AIM_ACTIONS[aim_action])
        return actions

def print_game_info():
    """æ‰“å°æ¸¸æˆæ§åˆ¶ä¿¡æ¯"""
    print("=" * 60)
    print("ğŸ® å¦å…‹æ¸¸æˆAIè§‚çœ‹æ¨¡å¼")
    print("=" * 60)
    print("æ§åˆ¶è¯´æ˜:")
    print("  - ç©ºæ ¼é”®: æš‚åœ/ç»§ç»­")
    print("  - Ré”®: é‡æ–°å¼€å§‹")
    print("  - Qé”®: é€€å‡º")
    print("  - Hé”®: æ˜¾ç¤º/éšè—AIæ€è€ƒä¿¡æ¯")
    print()
    print("æ¸¸æˆä¿¡æ¯:")
    print("  - ç»¿è‰²å¦å…‹: AIæ§åˆ¶çš„ç©å®¶")
    print("  - è“è‰²å¦å…‹: æ•Œæ–¹AI")
    print("  - é»„è‰²åœ†ç‚¹: ç©å®¶å­å¼¹")
    print("  - çº¢è‰²åœ†ç‚¹: æ•Œæ–¹å­å¼¹")
    print("=" * 60)
    print()

def analyze_ai_thinking(agent, state, movement_action, aim_action):
    """åˆ†æAIçš„æ€è€ƒè¿‡ç¨‹"""
    state_tensor = torch.FloatTensor(state).unsqueeze(0)
    
    with torch.no_grad():
        movement_q, aim_q = self.model(state_tensor)
    
    # è§£æåŠ¨ä½œåç§°
    movement_names = ["é™æ­¢", "å‘ä¸Š", "å‘ä¸‹", "å‘å·¦", "å‘å³"]
    aim_names = ["ç‚®ç®¡å·¦è½¬", "ç‚®ç®¡å³è½¬", "å°„å‡»"]
    
    print(f"ğŸ¤– AIæ€è€ƒåˆ†æ:")
    print(f"   ç§»åŠ¨Qå€¼: {[f'{q:.2f}' for q in movement_q[0].tolist()]}")
    print(f"   ç„å‡†Qå€¼: {[f'{q:.2f}' for q in aim_q[0].tolist()]}")
    print(f"   é€‰æ‹©çš„ç§»åŠ¨: {movement_names[movement_action]} (Qå€¼={movement_q[0][movement_action]:.2f})")
    print(f"   é€‰æ‹©çš„ç„å‡†: {aim_names[aim_action]} (Qå€¼={aim_q[0][aim_action]:.2f})")
    
    # åˆ†ææ¸¸æˆçŠ¶æ€
    player_x = state[0] * tankgame.SCREEN_WIDTH
    player_y = state[1] * tankgame.SCREEN_HEIGHT
    player_lives = state[3] * 5
    
    if state[11] > 0.5:  # æœ‰æ•Œäºº
        enemy_x = state[5] * tankgame.SCREEN_WIDTH
        enemy_y = state[6] * tankgame.SCREEN_HEIGHT
        distance = state[7] * tankgame.get_screen_diag()
        print(f"   æˆ˜æœ¯åˆ†æ: ç©å®¶ä½ç½®({player_x:.0f},{player_y:.0f}), "
              f"æ•Œäººä½ç½®({enemy_x:.0f},{enemy_y:.0f}), è·ç¦»{distance:.0f}")
    
    print(f"   ç”Ÿå­˜çŠ¶æ€: ç”Ÿå‘½å€¼{player_lives:.0f}, "
          f"æ—¶é—´å‰©ä½™{state[32] * tankgame.GAME_TIME_LIMIT:.0f}ç§’")
    print("-" * 40)

def watch_ai_play(args):
    """è§‚çœ‹AIç©æ¸¸æˆçš„ä¸»å‡½æ•°"""
    
    # æ‰“å°æ¸¸æˆä¿¡æ¯
    print_game_info()
    
    # åˆ›å»ºæ¸¸æˆå’Œæ™ºèƒ½ä½“
    game = tankgame.TankGame(render=True)
    agent = DemoAgent(args.model)
    
    # æ¸¸æˆç»Ÿè®¡
    episode_count = 0
    total_score = 0
    best_score = 0
    
    # æ§åˆ¶å˜é‡
    paused = False
    show_thinking = args.verbose
    auto_restart = args.auto_restart
    
    print(f"ğŸ¯ å¼€å§‹è§‚çœ‹AIæ¸¸æˆ...")
    print(f"   è‡ªåŠ¨é‡å¯: {'å¼€å¯' if auto_restart else 'å…³é—­'}")
    print(f"   æ˜¾ç¤ºæ€è€ƒ: {'å¼€å¯' if show_thinking else 'å…³é—­'}")
    print()
    
    try:
        while True:
            episode_count += 1
            state = game.reset()
            episode_score = 0
            step_count = 0
            
            print(f"ğŸ“ ç¬¬ {episode_count} å±€å¼€å§‹")
            
            # æ¸¸æˆä¸»å¾ªç¯
            while True:
                # å¤„ç†äº‹ä»¶
                for event in tankgame.pygame.event.get():
                    if event.type == tankgame.pygame.QUIT:
                        print("ğŸ‘‹ é€€å‡ºè§‚çœ‹")
                        return
                    elif event.type == tankgame.pygame.KEYDOWN:
                        if event.key == tankgame.pygame.K_q:
                            print("ğŸ‘‹ é€€å‡ºè§‚çœ‹")
                            return
                        elif event.key == tankgame.pygame.K_SPACE:
                            paused = not paused
                            print(f"â¸ï¸  {'æš‚åœ' if paused else 'ç»§ç»­'}")
                        elif event.key == tankgame.pygame.K_r:
                            print("ğŸ”„ æ‰‹åŠ¨é‡æ–°å¼€å§‹")
                            game.reset()
                            state = game.get_state()
                        elif event.key == tankgame.pygame.K_h:
                            show_thinking = not show_thinking
                            print(f"ğŸ’­ æ€è€ƒä¿¡æ¯: {'æ˜¾ç¤º' if show_thinking else 'éšè—'}")
                
                if paused:
                    tankgame.pygame.time.wait(100)
                    continue
                
                # AIå†³ç­–
                movement_action, aim_action = agent.get_action(state)
                actions = agent.get_combined_action(movement_action, aim_action)
                
                # æ˜¾ç¤ºAIæ€è€ƒè¿‡ç¨‹
                if show_thinking and step_count % 30 == 0:  # æ¯30å¸§æ˜¾ç¤ºä¸€æ¬¡
                    analyze_ai_thinking(agent, state, movement_action, aim_action)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                game.do_actions(actions)
                reward, done = game.step()
                next_state = game.get_state()
                
                episode_score += reward
                step_count += 1
                state = next_state
                
                # æ¸¸æˆç»“æŸå¤„ç†
                if done:
                    total_score += game.score
                    if game.score > best_score:
                        best_score = game.score
                    
                    print(f"ğŸ ç¬¬ {episode_count} å±€ç»“æŸ")
                    print(f"   æ¸¸æˆåˆ†æ•°: {game.score}")
                    print(f"   å›åˆå¥–åŠ±: {episode_score:.1f}")
                    print(f"   æ€»æ­¥æ•°: {step_count}")
                    print(f"   å†å²æœ€ä½³: {best_score}")
                    print(f"   å¹³å‡åˆ†æ•°: {total_score/episode_count:.1f}")
                    print()
                    
                    # è‡ªåŠ¨é‡å¯æˆ–ç­‰å¾…
                    if auto_restart:
                        tankgame.pygame.time.wait(2000)  # ç­‰å¾…2ç§’
                        break
                    else:
                        print("æŒ‰Ré”®é‡æ–°å¼€å§‹ï¼ŒQé”®é€€å‡º")
                        # ç­‰å¾…ç”¨æˆ·è¾“å…¥
                        waiting = True
                        while waiting:
                            for event in tankgame.pygame.event.get():
                                if event.type == tankgame.pygame.QUIT:
                                    return
                                elif event.type == tankgame.pygame.KEYDOWN:
                                    if event.key == tankgame.pygame.K_q:
                                        return
                                    elif event.key == tankgame.pygame.K_r:
                                        waiting = False
                                        break
                            tankgame.pygame.time.wait(100)
                        break
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ è§‚çœ‹è¢«ä¸­æ–­")
    
    # æœ€ç»ˆç»Ÿè®¡
    print("=" * 60)
    print("ğŸ“Š è§‚çœ‹ç»Ÿè®¡:")
    print(f"   æ€»å±€æ•°: {episode_count}")
    print(f"   å¹³å‡åˆ†æ•°: {total_score/episode_count:.1f}")
    print(f"   æœ€ä½³åˆ†æ•°: {best_score}")
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è§‚çœ‹è®­ç»ƒå¥½çš„AIç©å¦å…‹æ¸¸æˆ")
    parser.add_argument("--model", default="compact_robust_model.pth", 
                       help="æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: compact_robust_model.pth)")
    parser.add_argument("--auto-restart", action="store_true",
                       help="æ¸¸æˆç»“æŸåè‡ªåŠ¨é‡æ–°å¼€å§‹")
    parser.add_argument("--verbose", action="store_true",
                       help="æ˜¾ç¤ºAIçš„è¯¦ç»†æ€è€ƒè¿‡ç¨‹")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    try:
        torch.load(args.model, map_location='cpu')
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {args.model}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œæˆ–ä½¿ç”¨ --model å‚æ•°æŒ‡å®šæ­£ç¡®çš„è·¯å¾„")
        return
    
    # å¼€å§‹è§‚çœ‹
    watch_ai_play(args)

if __name__ == "__main__":
    main()